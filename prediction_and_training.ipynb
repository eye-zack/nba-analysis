{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0bff2-9006-4aaf-95ad-2b6d60b041c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d87b4ba-f87a-411b-875e-4f6753e762a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:01:15,296 - INFO - Dataset loaded: nba_historical_stats.csv\n",
      "2025-03-26 19:01:15,303 - INFO - Team totals separated from player data.\n",
      "2025-03-26 19:01:15,308 - INFO - Columns removed: ['Age', 'Rk', 'Player', 'TEAM']\n",
      "2025-03-26 19:01:15,364 - INFO - Missing values handled using median strategy.\n",
      "2025-03-26 19:01:15,376 - INFO - X_train shape: (16531, 20)\n",
      "2025-03-26 19:03:57,451 - INFO - Selected features: Index(['GS', 'FG%', '3PA', '3P%', 'AST'], dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Selected Important Features:\n",
      "Index(['GS', 'FG%', '3PA', '3P%', 'AST'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:04:10,166 - INFO - Best Model (Gradient Boosting) saved as '3P_best_model.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MAE: 0.0111, R²: 0.9983, Training Time: 6.72 sec\n",
      "Gradient Boosting - MAE: 0.0161, R²: 0.9983, Training Time: 5.84 sec\n",
      "Training is complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "input_csv = \"nba_historical_stats.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(input_csv)\n",
    "    logging.info(f\"Dataset loaded: {input_csv}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Dataset not found: {input_csv}\")\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# DB_CONNECTION = \"mysql+mysqlconnector://root:Adex127!Apple@localhost:3306/nba_analysis\" # Change creds\n",
    "# TABLE_NAME = \"historical_data_table\"\n",
    "\n",
    "# engine = create_engine(DB_CONNECTION)\n",
    "# try:\n",
    "#     with engine.connect() as connection:\n",
    "#         df = pd.read_sql(f\"SELECT * FROM {TABLE_NAME} WHERE Player != 'Team Totals'\", con=connection)\n",
    "#     logging.info(f\"Dataset loaded: {TABLE_NAME}\")\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"Dataset not loaded: {e}\")\n",
    "#     raise SystemExit\n",
    "\n",
    "df_team_totals = df[df[\"Player\"] == \"Team Totals\"]\n",
    "df_players = df[df[\"Player\"] != \"Team Totals\"]\n",
    "df = df_players.copy()\n",
    "logging.info(\"Team totals separated from player data.\")\n",
    "\n",
    "remove_columns = [\"Age\",\"Rk\",\"Player\",\"TEAM\"]\n",
    "df.drop(columns=remove_columns, inplace=True)\n",
    "logging.info(f\"Columns removed: {remove_columns}\")\n",
    "\n",
    "numeric_features = df.select_dtypes(include=np.number).columns\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "logging.info(f\"Missing values handled using median strategy.\")\n",
    "\n",
    "#df.drop_duplicates(inplace=True)\n",
    "#df.loc[:, df.select_dtypes(include=[np.number]).columns] = df.select_dtypes(include=[np.number]).fillna(df.mean())\n",
    "#df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "target_column = \"3P\"\n",
    "if target_column not in df.columns:\n",
    "    logging.error(f\"Column {target_column} not found in dataset\")\n",
    "    raise ValueError(\"Target column not found\")\n",
    "\n",
    "x = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "logging.info(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# Feature Selection\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Forest Regression\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "selector = RFECV(estimator=rf_model, step=5, cv=5, scoring=\"r2\", n_jobs=-1, min_features_to_select=5)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "logging.info(f\"Selected features: {selected_features}\")\n",
    "\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "\n",
    "print(\"\\n Selected Important Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_test_selected)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# Uncomment to compare forest regression and gradient boosting (Forest regression was best)\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model.fit(X_train_selected, y_train)\n",
    "gb_time = time.time() - start_time\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test_selected)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "#print(f\"Training is complete\")\n",
    "#print(f\"MAE: {mae}\")\n",
    "#print(f\"R2: {r2}\")\n",
    "\n",
    "print(f\"Random Forest - MAE: {rf_mae:.4f}, R²: {rf_r2:.4f}, Training Time: {rf_time:.2f} sec\")\n",
    "print(f\"Gradient Boosting - MAE: {gb_mae:.4f}, R²: {gb_r2:.4f}, Training Time: {gb_time:.2f} sec\")\n",
    "\n",
    "# Save the Best Model\n",
    "if rf_r2 > gb_r2:\n",
    "    joblib.dump(rf_model, \"3P_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Random Forest) saved as '3P_best_model.pkl'\")\n",
    "else:\n",
    "    joblib.dump(gb_model, \"3P_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Gradient Boosting) saved as '3P_best_model.pkl'\")\n",
    "\n",
    "# Uncomment these after testing Forest and boosting\n",
    "#joblib.dump(scaler, \"scaler.pkl\")\n",
    "#joblib.dump(model, \"model.pkl\")\n",
    "\n",
    "#logging.info(f\"Model saved: {model}\")\n",
    "print(f\"Training is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7db1f3-59e2-411e-9e82-90cc0e724c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:06:38,125 - INFO - Loading trained model\n",
      "2025-03-26 19:06:38,164 - INFO - Retrieved 5 features from model\n",
      "2025-03-26 19:06:38,164 - INFO - Loading historical data from nba_historical_stats.csv\n",
      "2025-03-26 19:06:38,268 - INFO - Recreating preprocessing steps from training\n",
      "2025-03-26 19:06:38,344 - INFO - Scaler recreated with historical data\n",
      "2025-03-26 19:06:38,345 - INFO - Loading new player data from nba_player_stats_nba_api_2024-25.csv\n",
      "2025-03-26 19:06:38,352 - INFO - Removing 3P column from new data as it's the prediction target\n",
      "2025-03-26 19:06:38,361 - INFO - Scaling features and selecting relevant ones\n",
      "2025-03-26 19:06:38,365 - INFO - Making predictions\n",
      "2025-03-26 19:06:38,373 - INFO - Prediction complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 players by predicted 3P:\n",
      "              Player  Predicted_3P TEAM\n",
      "489    Stephen Curry      4.386015  GSW\n",
      "57    Brandon Miller      4.209706  CHA\n",
      "29   Anthony Edwards      4.031296  MIN\n",
      "347      LaMelo Ball      4.012969  CHA\n",
      "370    Malik Beasley      3.799367  DET\n",
      "258     Jayson Tatum      3.773868  BOS\n",
      "138    Derrick White      3.483326  BOS\n",
      "528      Tyler Herro      3.401465  MIA\n",
      "360      Luka Dončić      3.358819  LAL\n",
      "111   Damian Lillard      3.346964  MIL\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "def predict_3p_for_new_season(new_data_path, historical_data_path, player_names_included=True):\n",
    "    \"\"\"\n",
    "    Predict 3P for NBA players in the 2025-26 season without relying on saved scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    new_data_path (str): Path to the CSV file containing new player stats\n",
    "    historical_data_path (str): Path to the CSV file containing historical stats used for training\n",
    "    player_names_included (bool): Whether the input CSV contains player names\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame with player names and predicted 3P\n",
    "    \"\"\"\n",
    "    # load the model that we got from the training program \n",
    "    logging.info(\"Loading trained model\")\n",
    "    best_model = joblib.load(\"3P_best_model.pkl\")\n",
    "    \n",
    "    # get the selected features by looking at the model's feature names\n",
    "    try:\n",
    "        selected_features = best_model.feature_names_in_\n",
    "        logging.info(f\"Retrieved {len(selected_features)} features from model\")\n",
    "    except AttributeError:\n",
    "        # ff feature names aren't stored in the model, we need to reconstruct the feature selection process\n",
    "        logging.warning(\"Model doesn't contain feature names, using hardcoded selected features\")\n",
    "        # replace with the actual features printed during training\n",
    "        selected_features = [\n",
    "            'GS', 'FG', 'FGA', 'FG%', '3PA', '3P%', 'ORB', 'AST', 'PF', 'YR'\n",
    "        ]\n",
    "    \n",
    "    # load historical data to recreate the scaler\n",
    "    logging.info(f\"Loading historical data from {historical_data_path}\")\n",
    "    try:\n",
    "        historical_df = pd.read_csv(historical_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Historical dataset not found: {historical_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store target column separately\n",
    "    target_column = \"3P\"\n",
    "    \n",
    "    # filter out team totals as we did in the training_program\n",
    "    historical_df = historical_df[historical_df[\"Player\"] != \"Team Totals\"].copy()\n",
    "    \n",
    "    # remove columns that we do not need for prediction\n",
    "    remove_columns = [\"Age\", \"Rk\", \"Player\", \"TEAM\"]\n",
    "    historical_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # drop the target column (3P) before preprocessing\n",
    "    x_historical = historical_df.drop(columns=[target_column])\n",
    "    \n",
    "    # recreate the imputer and scaler on historical data\n",
    "    logging.info(\"Recreating preprocessing steps from training\")\n",
    "    numeric_features = x_historical.select_dtypes(include=np.number).columns\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    x_historical[numeric_features] = imputer.fit_transform(x_historical[numeric_features])\n",
    "    \n",
    "    # recreate the scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_historical)\n",
    "    logging.info(\"Scaler recreated with historical data\")\n",
    "    \n",
    "    # load and prepare new player data\n",
    "    logging.info(f\"Loading new player data from {new_data_path}\")\n",
    "    try:\n",
    "        new_players_df = pd.read_csv(new_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {new_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store player names if included in the input\n",
    "    if player_names_included:\n",
    "        player_names = new_players_df[\"Player\"].copy()\n",
    "        team_names = new_players_df[\"TEAM\"].copy() if \"TEAM\" in new_players_df.columns else None\n",
    "    \n",
    "    # remove columns not used in training\n",
    "    new_players_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # remove the target column from new data if it exists\n",
    "    if target_column in new_players_df.columns:\n",
    "        logging.info(f\"Removing {target_column} column from new data as it's the prediction target\")\n",
    "        new_players_df.drop(columns=[target_column], inplace=True)\n",
    "    \n",
    "    # ensure the new data has exactly the same columns as the training data\n",
    "    missing_cols = set(x_historical.columns) - set(new_players_df.columns)\n",
    "    if missing_cols:\n",
    "        logging.warning(f\"Missing columns in new data: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            new_players_df[col] = 0  # Fill with zeros as placeholder\n",
    "    \n",
    "    # ensure columns are in the same order\n",
    "    new_players_df = new_players_df[x_historical.columns]\n",
    "    \n",
    "    # handle missing values\n",
    "    numeric_features = new_players_df.select_dtypes(include=np.number).columns\n",
    "    new_players_df[numeric_features] = imputer.transform(new_players_df[numeric_features])\n",
    "    \n",
    "    # transform and select features\n",
    "    logging.info(\"Scaling features and selecting relevant ones\")\n",
    "    new_players_scaled = pd.DataFrame(\n",
    "        scaler.transform(new_players_df), \n",
    "        columns=new_players_df.columns\n",
    "    )\n",
    "    \n",
    "    # ensure only selected features are used\n",
    "    if set(selected_features).issubset(set(new_players_scaled.columns)):\n",
    "        new_players_selected = new_players_scaled[selected_features]\n",
    "    else:\n",
    "        logging.error(f\"Selected features {selected_features} not found in scaled data columns: {new_players_scaled.columns}\")\n",
    "        raise ValueError(\"Feature mismatch between model and input data\")\n",
    "    \n",
    "    # make predictions\n",
    "    logging.info(\"Making predictions\")\n",
    "    predicted_3p = best_model.predict(new_players_selected)\n",
    "    \n",
    "    # create results dataframe\n",
    "    if player_names_included:\n",
    "        results = {\n",
    "            \"Player\": player_names,\n",
    "            \"Predicted_3P\": predicted_3p\n",
    "        }\n",
    "        if team_names is not None:\n",
    "            results[\"TEAM\"] = team_names\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "    else:\n",
    "        results_df = pd.DataFrame({\"Predicted_3P\": predicted_3p})\n",
    "    \n",
    "    logging.info(\"Prediction complete\")\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    historical_data_path = \"nba_historical_stats.csv\"  # same file used for training\n",
    "    new_data_path = \"nba_player_stats_nba_api_2024-25.csv\"  # data for predictions\n",
    "    \n",
    "    predictions = predict_3p_for_new_season(new_data_path, historical_data_path)\n",
    "    \n",
    "    # save predictions\n",
    "    predictions.to_csv(\"predicted_3p_2025-26.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nTop 10 players by predicted 3P:\")\n",
    "    print(predictions.sort_values(\"Predicted_3P\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299a3e6-f7c6-40a7-b49c-a38a544a8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bfc651-aac0-4679-b68d-ccd7ff4d0031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:06:45,423 - INFO - Dataset loaded: nba_historical_stats.csv\n",
      "2025-03-26 19:06:45,433 - INFO - Team totals separated from player data.\n",
      "2025-03-26 19:06:45,437 - INFO - Columns removed: ['Age', 'Rk', 'Player', 'TEAM']\n",
      "2025-03-26 19:06:45,521 - INFO - Missing values handled using median strategy.\n",
      "2025-03-26 19:06:45,536 - INFO - X_train shape: (16531, 20)\n",
      "2025-03-26 19:09:38,866 - INFO - Selected features: Index(['GS', 'FG', 'FGA', 'FG%', '3P', '3P%', 'ORB', 'AST', 'PF', 'YR'], dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Selected Important Features:\n",
      "Index(['GS', 'FG', 'FGA', 'FG%', '3P', '3P%', 'ORB', 'AST', 'PF', 'YR'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:10:01,770 - INFO - Best Model (Gradient Boosting) saved as '3PA_best_model.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MAE: 0.0734, R²: 0.9958, Training Time: 13.38 sec\n",
      "Gradient Boosting - MAE: 0.0744, R²: 0.9958, Training Time: 9.34 sec\n",
      "Training is complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "input_csv = \"nba_historical_stats.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(input_csv)\n",
    "    logging.info(f\"Dataset loaded: {input_csv}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Dataset not found: {input_csv}\")\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# DB_CONNECTION = \"mysql+mysqlconnector://root:Adex127!Apple@localhost:3306/nba_analysis\" # Change creds\n",
    "# TABLE_NAME = \"historical_data_table\"\n",
    "\n",
    "# engine = create_engine(DB_CONNECTION)\n",
    "# try:\n",
    "#     with engine.connect() as connection:\n",
    "#         df = pd.read_sql(f\"SELECT * FROM {TABLE_NAME} WHERE Player != 'Team Totals'\", con=connection)\n",
    "#     logging.info(f\"Dataset loaded: {TABLE_NAME}\")\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"Dataset not loaded: {e}\")\n",
    "#     raise SystemExit\n",
    "\n",
    "df_team_totals = df[df[\"Player\"] == \"Team Totals\"]\n",
    "df_players = df[df[\"Player\"] != \"Team Totals\"]\n",
    "df = df_players.copy()\n",
    "logging.info(\"Team totals separated from player data.\")\n",
    "\n",
    "remove_columns = [\"Age\",\"Rk\",\"Player\",\"TEAM\"]\n",
    "df.drop(columns=remove_columns, inplace=True)\n",
    "logging.info(f\"Columns removed: {remove_columns}\")\n",
    "\n",
    "numeric_features = df.select_dtypes(include=np.number).columns\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "logging.info(f\"Missing values handled using median strategy.\")\n",
    "\n",
    "#df.drop_duplicates(inplace=True)\n",
    "#df.loc[:, df.select_dtypes(include=[np.number]).columns] = df.select_dtypes(include=[np.number]).fillna(df.mean())\n",
    "#df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "target_column = \"3PA\"\n",
    "if target_column not in df.columns:\n",
    "    logging.error(f\"Column {target_column} not found in dataset\")\n",
    "    raise ValueError(\"Target column not found\")\n",
    "\n",
    "x = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "logging.info(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# Feature Selection\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Forest Regression\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "selector = RFECV(estimator=rf_model, step=5, cv=5, scoring=\"r2\", n_jobs=-1, min_features_to_select=5)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "logging.info(f\"Selected features: {selected_features}\")\n",
    "\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "\n",
    "print(\"\\n Selected Important Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_test_selected)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# Uncomment to compare forest regression and gradient boosting (Forest regression was best)\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model.fit(X_train_selected, y_train)\n",
    "gb_time = time.time() - start_time\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test_selected)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "#print(f\"Training is complete\")\n",
    "#print(f\"MAE: {mae}\")\n",
    "#print(f\"R2: {r2}\")\n",
    "\n",
    "print(f\"Random Forest - MAE: {rf_mae:.4f}, R²: {rf_r2:.4f}, Training Time: {rf_time:.2f} sec\")\n",
    "print(f\"Gradient Boosting - MAE: {gb_mae:.4f}, R²: {gb_r2:.4f}, Training Time: {gb_time:.2f} sec\")\n",
    "\n",
    "# Save the Best Model\n",
    "if rf_r2 > gb_r2:\n",
    "    joblib.dump(rf_model, \"3PA_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Random Forest) saved as '3PA_best_model.pkl'\")\n",
    "else:\n",
    "    joblib.dump(gb_model, \"3PA_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Gradient Boosting) saved as '3PA_best_model.pkl'\")\n",
    "\n",
    "# Uncomment these after testing Forest and boosting\n",
    "#joblib.dump(scaler, \"scaler.pkl\")\n",
    "#joblib.dump(model, \"model.pkl\")\n",
    "\n",
    "#logging.info(f\"Model saved: {model}\")\n",
    "print(f\"Training is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e20780d-957a-4fbf-ac02-fd4ccb4fe433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:12:06,389 - INFO - Loading trained model\n",
      "2025-03-26 19:12:06,414 - INFO - Retrieved 10 features from model\n",
      "2025-03-26 19:12:06,415 - INFO - Loading historical data from nba_historical_stats.csv\n",
      "2025-03-26 19:12:06,500 - INFO - Recreating preprocessing steps from training\n",
      "2025-03-26 19:12:06,579 - INFO - Scaler recreated with historical data\n",
      "2025-03-26 19:12:06,579 - INFO - Loading new player data from nba_player_stats_nba_api_2024-25.csv\n",
      "2025-03-26 19:12:06,586 - INFO - Removing 3PA column from new data as it's the prediction target\n",
      "2025-03-26 19:12:06,594 - INFO - Scaling features and selecting relevant ones\n",
      "2025-03-26 19:12:06,598 - INFO - Making predictions\n",
      "2025-03-26 19:12:06,606 - INFO - Prediction complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 players by predicted 3PA:\n",
      "               Player  Predicted_3PA TEAM\n",
      "347       LaMelo Ball      11.035712  CHA\n",
      "489     Stephen Curry      10.933861  GSW\n",
      "29    Anthony Edwards      10.275397  MIN\n",
      "57     Brandon Miller      10.178646  CHA\n",
      "258      Jayson Tatum       9.707881  BOS\n",
      "360       Luka Dončić       9.579534  LAL\n",
      "528       Tyler Herro       9.239410  MIA\n",
      "370     Malik Beasley       9.206399  DET\n",
      "287      Jordan Poole       9.130966  WAS\n",
      "148  Donovan Mitchell       9.115890  CLE\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "def predict_3pa_for_new_season(new_data_path, historical_data_path, player_names_included=True):\n",
    "    \"\"\"\n",
    "    Predict 3PA for NBA players in the 2025-26 season without relying on saved scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    new_data_path (str): Path to the CSV file containing new player stats\n",
    "    historical_data_path (str): Path to the CSV file containing historical stats used for training\n",
    "    player_names_included (bool): Whether the input CSV contains player names\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame with player names and predicted 3PA\n",
    "    \"\"\"\n",
    "    # load the model that we got from the training program \n",
    "    logging.info(\"Loading trained model\")\n",
    "    best_model = joblib.load(\"3PA_best_model.pkl\")\n",
    "    \n",
    "    # get the selected features by looking at the model's feature names\n",
    "    try:\n",
    "        selected_features = best_model.feature_names_in_\n",
    "        logging.info(f\"Retrieved {len(selected_features)} features from model\")\n",
    "    except AttributeError:\n",
    "        # ff feature names aren't stored in the model, we need to reconstruct the feature selection process\n",
    "        logging.warning(\"Model doesn't contain feature names, using hardcoded selected features\")\n",
    "        # replace with the actual features printed during training\n",
    "        selected_features = [\n",
    "            'GS', 'FG', 'FGA', 'FG%', '3P', '3P%', 'ORB', 'AST', 'PF', 'YR'\n",
    "        ]\n",
    "    \n",
    "    # load historical data to recreate the scaler\n",
    "    logging.info(f\"Loading historical data from {historical_data_path}\")\n",
    "    try:\n",
    "        historical_df = pd.read_csv(historical_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Historical dataset not found: {historical_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store target column separately\n",
    "    target_column = \"3PA\"\n",
    "    \n",
    "    # filter out team totals as we did in the training_program\n",
    "    historical_df = historical_df[historical_df[\"Player\"] != \"Team Totals\"].copy()\n",
    "    \n",
    "    # remove columns that we do not need for prediction\n",
    "    remove_columns = [\"Age\", \"Rk\", \"Player\", \"TEAM\"]\n",
    "    historical_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # drop the target column (3PA) before preprocessing\n",
    "    x_historical = historical_df.drop(columns=[target_column])\n",
    "    \n",
    "    # recreate the imputer and scaler on historical data\n",
    "    logging.info(\"Recreating preprocessing steps from training\")\n",
    "    numeric_features = x_historical.select_dtypes(include=np.number).columns\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    x_historical[numeric_features] = imputer.fit_transform(x_historical[numeric_features])\n",
    "    \n",
    "    # recreate the scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_historical)\n",
    "    logging.info(\"Scaler recreated with historical data\")\n",
    "    \n",
    "    # load and prepare new player data\n",
    "    logging.info(f\"Loading new player data from {new_data_path}\")\n",
    "    try:\n",
    "        new_players_df = pd.read_csv(new_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {new_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store player names if included in the input\n",
    "    if player_names_included:\n",
    "        player_names = new_players_df[\"Player\"].copy()\n",
    "        team_names = new_players_df[\"TEAM\"].copy() if \"TEAM\" in new_players_df.columns else None\n",
    "    \n",
    "    # remove columns not used in training\n",
    "    new_players_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # remove the target column from new data if it exists\n",
    "    if target_column in new_players_df.columns:\n",
    "        logging.info(f\"Removing {target_column} column from new data as it's the prediction target\")\n",
    "        new_players_df.drop(columns=[target_column], inplace=True)\n",
    "    \n",
    "    # ensure the new data has exactly the same columns as the training data\n",
    "    missing_cols = set(x_historical.columns) - set(new_players_df.columns)\n",
    "    if missing_cols:\n",
    "        logging.warning(f\"Missing columns in new data: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            new_players_df[col] = 0  # Fill with zeros as placeholder\n",
    "    \n",
    "    # ensure columns are in the same order\n",
    "    new_players_df = new_players_df[x_historical.columns]\n",
    "    \n",
    "    # handle missing values\n",
    "    numeric_features = new_players_df.select_dtypes(include=np.number).columns\n",
    "    new_players_df[numeric_features] = imputer.transform(new_players_df[numeric_features])\n",
    "    \n",
    "    # transform and select features\n",
    "    logging.info(\"Scaling features and selecting relevant ones\")\n",
    "    new_players_scaled = pd.DataFrame(\n",
    "        scaler.transform(new_players_df), \n",
    "        columns=new_players_df.columns\n",
    "    )\n",
    "    \n",
    "    # ensure only selected features are used\n",
    "    if set(selected_features).issubset(set(new_players_scaled.columns)):\n",
    "        new_players_selected = new_players_scaled[selected_features]\n",
    "    else:\n",
    "        logging.error(f\"Selected features {selected_features} not found in scaled data columns: {new_players_scaled.columns}\")\n",
    "        raise ValueError(\"Feature mismatch between model and input data\")\n",
    "    \n",
    "    # make predictions\n",
    "    logging.info(\"Making predictions\")\n",
    "    predicted_3pa = best_model.predict(new_players_selected)\n",
    "    \n",
    "    # create results dataframe\n",
    "    if player_names_included:\n",
    "        results = {\n",
    "            \"Player\": player_names,\n",
    "            \"Predicted_3PA\": predicted_3pa\n",
    "        }\n",
    "        if team_names is not None:\n",
    "            results[\"TEAM\"] = team_names\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "    else:\n",
    "        results_df = pd.DataFrame({\"Predicted_3PA\": predicted_3pa})\n",
    "    \n",
    "    logging.info(\"Prediction complete\")\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    historical_data_path = \"nba_historical_stats.csv\"  # same file used for training\n",
    "    new_data_path = \"nba_player_stats_nba_api_2024-25.csv\"  # data for predictions\n",
    "    \n",
    "    predictions = predict_3pa_for_new_season(new_data_path, historical_data_path)\n",
    "    \n",
    "    # save predictions\n",
    "    predictions.to_csv(\"predicted_3pa_2025-26.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nTop 10 players by predicted 3PA:\")\n",
    "    print(predictions.sort_values(\"Predicted_3PA\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad0148-223b-4fd5-b066-584ea59c4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3P%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19e1006-7431-4260-a152-088c6089fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:12:12,009 - INFO - Dataset loaded: nba_historical_stats.csv\n",
      "2025-03-26 19:12:12,019 - INFO - Team totals separated from player data.\n",
      "2025-03-26 19:12:12,022 - INFO - Columns removed: ['Age', 'Rk', 'Player', 'TEAM']\n",
      "2025-03-26 19:12:12,087 - INFO - Missing values handled using median strategy.\n",
      "2025-03-26 19:12:12,104 - INFO - X_train shape: (16531, 20)\n",
      "2025-03-26 19:14:38,994 - INFO - Selected features: Index(['GS', 'MP', 'FGA', 'FG%', '3P', '3PA', 'FTA', 'FT%', 'DRB', 'TRB',\n",
      "       'AST', 'STL', 'TOV', 'PF', 'YR'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Selected Important Features:\n",
      "Index(['GS', 'MP', 'FGA', 'FG%', '3P', '3PA', 'FTA', 'FT%', 'DRB', 'TRB',\n",
      "       'AST', 'STL', 'TOV', 'PF', 'YR'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:15:10,556 - INFO - Best Model (Random Forest) saved as '3PP_best_model.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MAE: 0.0515, R²: 0.6387, Training Time: 17.94 sec\n",
      "Gradient Boosting - MAE: 0.0528, R²: 0.6361, Training Time: 13.38 sec\n",
      "Training is complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "input_csv = \"nba_historical_stats.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(input_csv)\n",
    "    logging.info(f\"Dataset loaded: {input_csv}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Dataset not found: {input_csv}\")\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# DB_CONNECTION = \"mysql+mysqlconnector://root:Adex127!Apple@localhost:3306/nba_analysis\" # Change creds\n",
    "# TABLE_NAME = \"historical_data_table\"\n",
    "\n",
    "# engine = create_engine(DB_CONNECTION)\n",
    "# try:\n",
    "#     with engine.connect() as connection:\n",
    "#         df = pd.read_sql(f\"SELECT * FROM {TABLE_NAME} WHERE Player != 'Team Totals'\", con=connection)\n",
    "#     logging.info(f\"Dataset loaded: {TABLE_NAME}\")\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"Dataset not loaded: {e}\")\n",
    "#     raise SystemExit\n",
    "\n",
    "df_team_totals = df[df[\"Player\"] == \"Team Totals\"]\n",
    "df_players = df[df[\"Player\"] != \"Team Totals\"]\n",
    "df = df_players.copy()\n",
    "logging.info(\"Team totals separated from player data.\")\n",
    "\n",
    "remove_columns = [\"Age\",\"Rk\",\"Player\",\"TEAM\"]\n",
    "df.drop(columns=remove_columns, inplace=True)\n",
    "logging.info(f\"Columns removed: {remove_columns}\")\n",
    "\n",
    "numeric_features = df.select_dtypes(include=np.number).columns\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "logging.info(f\"Missing values handled using median strategy.\")\n",
    "\n",
    "#df.drop_duplicates(inplace=True)\n",
    "#df.loc[:, df.select_dtypes(include=[np.number]).columns] = df.select_dtypes(include=[np.number]).fillna(df.mean())\n",
    "#df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "target_column = \"3P%\"\n",
    "if target_column not in df.columns:\n",
    "    logging.error(f\"Column {target_column} not found in dataset\")\n",
    "    raise ValueError(\"Target column not found\")\n",
    "\n",
    "x = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "logging.info(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# Feature Selection\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Forest Regression\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "selector = RFECV(estimator=rf_model, step=5, cv=5, scoring=\"r2\", n_jobs=-1, min_features_to_select=5)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "logging.info(f\"Selected features: {selected_features}\")\n",
    "\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "\n",
    "print(\"\\n Selected Important Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_test_selected)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# Uncomment to compare forest regression and gradient boosting (Forest regression was best)\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model.fit(X_train_selected, y_train)\n",
    "gb_time = time.time() - start_time\n",
    "\n",
    "gb_y_pred = gb_model.predict(X_test_selected)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "#print(f\"Training is complete\")\n",
    "#print(f\"MAE: {mae}\")\n",
    "#print(f\"R2: {r2}\")\n",
    "\n",
    "print(f\"Random Forest - MAE: {rf_mae:.4f}, R²: {rf_r2:.4f}, Training Time: {rf_time:.2f} sec\")\n",
    "print(f\"Gradient Boosting - MAE: {gb_mae:.4f}, R²: {gb_r2:.4f}, Training Time: {gb_time:.2f} sec\")\n",
    "\n",
    "# Save the Best Model\n",
    "if rf_r2 > gb_r2:\n",
    "    joblib.dump(rf_model, \"3PP_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Random Forest) saved as '3PP_best_model.pkl'\")\n",
    "else:\n",
    "    joblib.dump(gb_model, \"3PP_best_model.pkl\")\n",
    "    logging.info(\"Best Model (Gradient Boosting) saved as '3PP_best_model.pkl'\")\n",
    "\n",
    "# Uncomment these after testing Forest and boosting\n",
    "#joblib.dump(scaler, \"scaler.pkl\")\n",
    "#joblib.dump(model, \"model.pkl\")\n",
    "\n",
    "#logging.info(f\"Model saved: {model}\")\n",
    "print(f\"Training is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926a0bd4-d346-4b95-93df-c06c7c404c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 19:42:14,283 - INFO - Loading trained model\n",
      "2025-03-26 19:42:14,400 - INFO - Retrieved 15 features from model\n",
      "2025-03-26 19:42:14,401 - INFO - Loading historical data from nba_historical_stats.csv\n",
      "2025-03-26 19:42:14,515 - INFO - Recreating preprocessing steps from training\n",
      "2025-03-26 19:42:14,588 - INFO - Scaler recreated with historical data\n",
      "2025-03-26 19:42:14,589 - INFO - Loading new player data from nba_player_stats_nba_api_2024-25.csv\n",
      "2025-03-26 19:42:14,596 - INFO - Removing 3P% column from new data as it's the prediction target\n",
      "2025-03-26 19:42:14,603 - INFO - Scaling features and selecting relevant ones\n",
      "2025-03-26 19:42:14,607 - INFO - Making predictions\n",
      "2025-03-26 19:42:14,656 - INFO - Prediction complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 players by predicted 3P%:\n",
      "                  Player  Predicted_3P% TEAM\n",
      "507         Tony Bradley       0.985000  IND\n",
      "18      Alondes Williams       0.979495  DET\n",
      "485      Skal Labissiere       0.961005  SAC\n",
      "433            PJ Dozier       0.573564  MIN\n",
      "14            Alex Ducas       0.520999  OKC\n",
      "388        Maxwell Lewis       0.516533  BKN\n",
      "377       Markelle Fultz       0.511609  SAC\n",
      "440  Patrick Baldwin Jr.       0.507365  LAC\n",
      "483         Sidy Cissoko       0.503255  POR\n",
      "155            Dru Smith       0.492179  MIA\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "def predict_3pp_for_new_season(new_data_path, historical_data_path, player_names_included=True):\n",
    "    \"\"\"\n",
    "    Predict 3P% for NBA players in the 2025-26 season without relying on saved scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    new_data_path (str): Path to the CSV file containing new player stats\n",
    "    historical_data_path (str): Path to the CSV file containing historical stats used for training\n",
    "    player_names_included (bool): Whether the input CSV contains player names\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame with player names and predicted 3P%\n",
    "    \"\"\"\n",
    "    # load the model that we got from the training program \n",
    "    logging.info(\"Loading trained model\")\n",
    "    best_model = joblib.load(\"3PP_best_model.pkl\")\n",
    "    \n",
    "    # get the selected features by looking at the model's feature names\n",
    "    try:\n",
    "        selected_features = best_model.feature_names_in_\n",
    "        logging.info(f\"Retrieved {len(selected_features)} features from model\")\n",
    "    except AttributeError:\n",
    "        # ff feature names aren't stored in the model, we need to reconstruct the feature selection process\n",
    "        logging.warning(\"Model doesn't contain feature names, using hardcoded selected features\")\n",
    "        # replace with the actual features printed during training\n",
    "        selected_features = [\n",
    "            'GS', 'FG', 'FGA', 'FG%', '3P', '3PA', 'ORB', 'AST', 'PF', 'YR'\n",
    "        ]\n",
    "    \n",
    "    # load historical data to recreate the scaler\n",
    "    logging.info(f\"Loading historical data from {historical_data_path}\")\n",
    "    try:\n",
    "        historical_df = pd.read_csv(historical_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Historical dataset not found: {historical_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store target column separately\n",
    "    target_column = \"3P%\"\n",
    "    \n",
    "    # filter out team totals as we did in the training_program\n",
    "    historical_df = historical_df[historical_df[\"Player\"] != \"Team Totals\"].copy()\n",
    "    \n",
    "    # remove columns that we do not need for prediction\n",
    "    remove_columns = [\"Age\", \"Rk\", \"Player\", \"TEAM\"]\n",
    "    historical_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # drop the target column (3P%) before preprocessing\n",
    "    x_historical = historical_df.drop(columns=[target_column])\n",
    "    \n",
    "    # recreate the imputer and scaler on historical data\n",
    "    logging.info(\"Recreating preprocessing steps from training\")\n",
    "    numeric_features = x_historical.select_dtypes(include=np.number).columns\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    x_historical[numeric_features] = imputer.fit_transform(x_historical[numeric_features])\n",
    "    \n",
    "    # recreate the scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_historical)\n",
    "    logging.info(\"Scaler recreated with historical data\")\n",
    "    \n",
    "    # load and prepare new player data\n",
    "    logging.info(f\"Loading new player data from {new_data_path}\")\n",
    "    try:\n",
    "        new_players_df = pd.read_csv(new_data_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {new_data_path}\")\n",
    "        raise SystemExit\n",
    "    \n",
    "    # store player names if included in the input\n",
    "    if player_names_included:\n",
    "        player_names = new_players_df[\"Player\"].copy()\n",
    "        team_names = new_players_df[\"TEAM\"].copy() if \"TEAM\" in new_players_df.columns else None\n",
    "    \n",
    "    # remove columns not used in training\n",
    "    new_players_df.drop(columns=remove_columns, inplace=True, errors='ignore')\n",
    "    \n",
    "    # remove the target column from new data if it exists\n",
    "    if target_column in new_players_df.columns:\n",
    "        logging.info(f\"Removing {target_column} column from new data as it's the prediction target\")\n",
    "        new_players_df.drop(columns=[target_column], inplace=True)\n",
    "    \n",
    "    # ensure the new data has exactly the same columns as the training data\n",
    "    missing_cols = set(x_historical.columns) - set(new_players_df.columns)\n",
    "    if missing_cols:\n",
    "        logging.warning(f\"Missing columns in new data: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            new_players_df[col] = 0  # Fill with zeros as placeholder\n",
    "    \n",
    "    # ensure columns are in the same order\n",
    "    new_players_df = new_players_df[x_historical.columns]\n",
    "    \n",
    "    # handle missing values\n",
    "    numeric_features = new_players_df.select_dtypes(include=np.number).columns\n",
    "    new_players_df[numeric_features] = imputer.transform(new_players_df[numeric_features])\n",
    "    \n",
    "    # transform and select features\n",
    "    logging.info(\"Scaling features and selecting relevant ones\")\n",
    "    new_players_scaled = pd.DataFrame(\n",
    "        scaler.transform(new_players_df), \n",
    "        columns=new_players_df.columns\n",
    "    )\n",
    "    \n",
    "    # ensure only selected features are used\n",
    "    if set(selected_features).issubset(set(new_players_scaled.columns)):\n",
    "        new_players_selected = new_players_scaled[selected_features]\n",
    "    else:\n",
    "        logging.error(f\"Selected features {selected_features} not found in scaled data columns: {new_players_scaled.columns}\")\n",
    "        raise ValueError(\"Feature mismatch between model and input data\")\n",
    "    \n",
    "    # make predictions\n",
    "    logging.info(\"Making predictions\")\n",
    "    predicted_3pp = best_model.predict(new_players_selected)\n",
    "    \n",
    "    # create results dataframe\n",
    "    if player_names_included:\n",
    "        results = {\n",
    "            \"Player\": player_names,\n",
    "            \"Predicted_3P%\": predicted_3pp\n",
    "        }\n",
    "        if team_names is not None:\n",
    "            results[\"TEAM\"] = team_names\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "    else:\n",
    "        results_df = pd.DataFrame({\"Predicted_3P%\": predicted_3pp})\n",
    "    \n",
    "    logging.info(\"Prediction complete\")\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    historical_data_path = \"nba_historical_stats.csv\"  # same file used for training\n",
    "    new_data_path = \"nba_player_stats_nba_api_2024-25.csv\"  # data for predictions\n",
    "    \n",
    "    predictions = predict_3pp_for_new_season(new_data_path, historical_data_path)\n",
    "    \n",
    "    # save predictions\n",
    "    predictions.to_csv(\"predicted_3pp_2025-26.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nTop 10 players by predicted 3P%:\")\n",
    "    print(predictions.sort_values(\"Predicted_3P%\", ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
